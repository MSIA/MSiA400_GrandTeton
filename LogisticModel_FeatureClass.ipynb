{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import cv2\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data is stored inside the 'team' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../team/courses/MSiA400/GrandTeton'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_real = path + '/Photos-20191020T020916Z-001/Photos/'\n",
    "path_generated_go = path + '/GO_noGO Data Set_Images/TestGo/'\n",
    "path_generated_nogo = path + '/GO_noGO Data Set_Images/TestNoGo/'\n",
    "\n",
    "# Set path for training images\n",
    "filepaths_go = [f for f in listdir(path_generated_go) if f.endswith('.png')]\n",
    "filepaths_nogo = [f for f in listdir(path_generated_nogo) if f.endswith('.png')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3370/3370 [00:28<00:00, 117.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read all GO and NoGO images into a list\n",
    "list_img = []\n",
    "for i in tqdm(filepaths_go):\n",
    "    list_img.append(cv2.imread(path_generated_go + i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5001/5001 [00:46<00:00, 107.63it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(filepaths_nogo):\n",
    "    list_img.append(cv2.imread(path_generated_nogo + i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(list_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8371"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Extractor:\n",
    "    # class defines feature extraction methods for extracting features out of an image\n",
    "    def __init__(self, threshold = 200, line_margin = 15, roof_margin = 10, corner_margin = 5):\n",
    "        self.threshold = threshold\n",
    "        self.line_margin = line_margin\n",
    "        self.roof_margin = roof_margin\n",
    "        self.corner_margin = corner_margin\n",
    "\n",
    "    def img_width(self, img):\n",
    "        return img.shape[1]\n",
    "    \n",
    "    def img_height(self, img):\n",
    "        return img.shape[0]\n",
    "\n",
    "    def count_level(self, img):\n",
    "        # Function that counts the number of floors\n",
    "        # Convert img to grayscale\n",
    "        gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Get shape\n",
    "        shape = gray.shape\n",
    "\n",
    "        # Get width of the image\n",
    "        width = shape[1]\n",
    "\n",
    "        # Detect edges\n",
    "        edges = cv2.Canny(gray, 80, 120)\n",
    "\n",
    "        #HoughLinesP returns an array of (rho, theta) values. \n",
    "        #rho is measured in pixels and theta is measured in radians\n",
    "\n",
    "        # Detect lines representing the floors which are longer than 80% of the width of the building\n",
    "        lines = cv2.HoughLinesP(edges, rho = 1, theta = math.pi/2, minLineLength = 0.8*width, threshold = 1, maxLineGap = 3)\n",
    "        \n",
    "        flags = [0]\n",
    "        if (type(lines) != type(None)):\n",
    "            lines.tolist()\n",
    "\n",
    "            # Delete repeated lines and line detected from the roof (we only need floor lines to count the number of floors)\n",
    "\n",
    "            flags = [0]*len(lines)  # flags will mark the redundant lines as 1, lines we need as 0\n",
    "            for i in range(len(lines)):\n",
    "                for j in range(len(lines)):\n",
    "                    if j < i and (abs(lines[i][0][1]-lines[j][0][1]) < self.line_margin):  # detect lines very close to each other \n",
    "                        flags[j] = 1\n",
    "                if abs(lines[i][0][1]-0) < self.roof_margin:  # roof lines: y Coordinate -> 0\n",
    "                    flags[i] = 1\n",
    "        counter = 0\n",
    "        for i in range(len(flags)):\n",
    "            if flags[i] == 0:\n",
    "                counter += 1                \n",
    "        return counter\n",
    "\n",
    "    def count_openings(self, img):\n",
    "        # Function that counts the number of openings in a house\n",
    "        # most of the openings are white rectangles which denote windows and gates\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        height = gray.shape[0]\n",
    "        width = gray.shape[1]\n",
    "\n",
    "        # threshold optimized (via hit and trial) for the generated images\n",
    "        ret,thresh = cv2.threshold(gray, self.threshold, 255, 0)\n",
    "        contours, h = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        quadrilaterals = []\n",
    "        for i in range(len(contours)):\n",
    "            polygon = cv2.approxPolyDP(contours[i],0.01*cv2.arcLength(contours[i],True),True)\n",
    "            if len(polygon) == 4:\n",
    "                quadrilaterals.append(polygon) \n",
    "        # Detect and delete quadrilaterals outside the house which should not be counted as openings\n",
    "        redflag = [0]*len(quadrilaterals)\n",
    "\n",
    "        for i in range(len(quadrilaterals)):\n",
    "            q = quadrilaterals[i]\n",
    "            for j in range(4):\n",
    "                if abs(q[j][0][0] - width) < self.corner_margin or abs(q[j][0][0]) < self.corner_margin:\n",
    "                    redflag[i] = 1\n",
    "\n",
    "        return (len(quadrilaterals) - np.sum(redflag))\n",
    "\n",
    "    def fraction_width(self, img):\n",
    "        # Function that calculates proportion of sum of all windows' widths (without overlap), on all floors \n",
    "        # to the overall wigth of building\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        height = gray.shape[0]\n",
    "        width = gray.shape[1]\n",
    "\n",
    "        # threshold optimized (via hit and trial) for the generated images\n",
    "        ret, thresh = cv2.threshold(gray, self.threshold, 255, 0)\n",
    "\n",
    "        # Contours is a tree of lists of points which describe each contour\n",
    "        contours, h = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Create a list storing quadrilaterals that represent openings\n",
    "        quadrilaterals = []\n",
    "        for i in range(len(contours)):\n",
    "\n",
    "            # Contour approximation will mark four vertices of a quadrilateral\n",
    "            polygon = cv2.approxPolyDP(contours[i],0.01*cv2.arcLength(contours[i],True),True)\n",
    "            # filtering only those openings that are quadrilaterals\n",
    "            if len(polygon) == 4:\n",
    "                quadrilaterals.append(polygon) \n",
    "\n",
    "        redflag = [0]*len(quadrilaterals)\n",
    "\n",
    "        # Detect and delete quadrilaterals outside the house which should not be counted as openings\n",
    "        for i in range(len(quadrilaterals)):\n",
    "            q = quadrilaterals[i]\n",
    "            for j in range(4):\n",
    "                if abs(q[j][0][0] - width) < self.corner_margin or abs(q[j][0][0]) < self.corner_margin:\n",
    "                    redflag[i] = 1\n",
    "\n",
    "        # Get a blank canvas for drawing width of a side of each quadrilateral\n",
    "        detection_series = np.zeros(width, dtype = 'uint8')\n",
    "\n",
    "        # The width of a side should be the larger x cordinate of the right vertics \n",
    "        # minus the x cordinate of the left vertics\n",
    "        for i in range(len(quadrilaterals)):\n",
    "            q = quadrilaterals[i]\n",
    "            if redflag[i]!=1:\n",
    "                x_min = np.min(q[:,0,0])\n",
    "                x_max = np.max(q[:,0,0])\n",
    "                detection_series[x_min:x_max] = np.ones(x_max-x_min, dtype = 'uint8')\n",
    "\n",
    "        # Return fraction of sum of all windows' widths (without overlap), on all floors to the overall width of building\n",
    "        return np.sum(detection_series)/width\n",
    "    \n",
    "    def avg_fraction_width(self, img):\n",
    "        # Function that calculates proportion of sum of all windows' widths (divided by the number of floors) \n",
    "        # to the overall length of building\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        height = gray.shape[0]\n",
    "        width = gray.shape[1]\n",
    "\n",
    "        # threshold optimized (via hit and trial) for the generated images\n",
    "        ret, thresh = cv2.threshold(gray, self.threshold, 255, 0)\n",
    "\n",
    "        # Contours is a tree of lists of points which describe each contour\n",
    "        contours, h = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Create a list storing quadrilaterals that represent openings\n",
    "        quadrilaterals = []\n",
    "        for i in range(len(contours)):\n",
    "\n",
    "            # Contour approximation will mark four vertices of a quadrilateral\n",
    "            polygon = cv2.approxPolyDP(contours[i],0.01*cv2.arcLength(contours[i],True),True)\n",
    "            # filtering only those openings that are quadrilaterals\n",
    "            if len(polygon) == 4:\n",
    "                quadrilaterals.append(polygon) \n",
    "\n",
    "        redflag = [0]*len(quadrilaterals)\n",
    "\n",
    "        # Detect and delete quadrilaterals outside the house which should not be counted as openings\n",
    "        for i in range(len(quadrilaterals)):\n",
    "            q = quadrilaterals[i]\n",
    "            for j in range(4):\n",
    "                if abs(q[j][0][0] - width) < self.corner_margin or abs(q[j][0][0]) < self.corner_margin:\n",
    "                    redflag[i] = 1\n",
    "\n",
    "        # set aggregate width = 0 before the loop that is going to account for the width of each opening\n",
    "        aggregate_width = 0;\n",
    "\n",
    "        # The width of a side should be the larger x cordinate of the right vertics \n",
    "        # minus the x cordinate of the left vertics\n",
    "        for i in range(len(quadrilaterals)):\n",
    "            q = quadrilaterals[i]\n",
    "            if redflag[i]!=1:\n",
    "                x_min = np.min(q[:,0,0])\n",
    "                x_max = np.max(q[:,0,0])\n",
    "                aggregate_width = aggregate_width + (x_max-x_min)\n",
    "\n",
    "        # now in order to calculate the average, we need the number of floors\n",
    "        num_levels = self.count_level(img)\n",
    "\n",
    "        # Return the ratio of: average of sum of all windows' widths (over all floors) to the total width of the building\n",
    "        return aggregate_width/(num_levels*width)\n",
    "    \n",
    "    def fraction_height(self, img):\n",
    "        # Function that calculates proportion of sum of all windows' heights (without overlap), on all floors\n",
    "        # to the overall length of building\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        height = gray.shape[0]\n",
    "        width = gray.shape[1]\n",
    "\n",
    "        # threshold optimized (via hit and trial) for the generated images\n",
    "        ret, thresh = cv2.threshold(gray, self.threshold, 255, 0)\n",
    "\n",
    "        # Contours is a tree of lists of points which describe each contour\n",
    "        contours, h = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Create a list storing quadrilaterals that represent openings\n",
    "        quadrilaterals = []\n",
    "        for i in range(len(contours)):\n",
    "\n",
    "            # Contour approximation will mark four vertices of a quadrilateral\n",
    "            polygon = cv2.approxPolyDP(contours[i],0.01*cv2.arcLength(contours[i],True),True)\n",
    "            # filtering only those openings that are quadrilaterals\n",
    "            if len(polygon) == 4:\n",
    "                quadrilaterals.append(polygon) \n",
    "\n",
    "        redflag = [0]*len(quadrilaterals)\n",
    "\n",
    "        # Detect and delete quadrilaterals outside the house which should not be counted as openings\n",
    "        for i in range(len(quadrilaterals)):\n",
    "            q = quadrilaterals[i]\n",
    "            for j in range(4):\n",
    "                if abs(q[j][0][0] - gray.shape[1]) < self.corner_margin or abs(q[j][0][0]) < self.corner_margin:\n",
    "                    redflag[i] = 1\n",
    "\n",
    "        # Get a blank canvas for drawing width of a side of each quadrilateral\n",
    "        detection_series = np.zeros(height, dtype = 'uint8')\n",
    "\n",
    "        # The height of a side should be the larger y cordinate of the top vertics \n",
    "        # minus the y cordinate of the bottom vertics\n",
    "        for i in range(len(quadrilaterals)):\n",
    "            q = quadrilaterals[i]\n",
    "            if redflag[i]!=1:\n",
    "                y_min = np.min(q[:,0,1])\n",
    "                y_max = np.max(q[:,0,1])\n",
    "                detection_series[y_min:y_max] = np.ones(y_max-y_min, dtype = 'uint8')\n",
    "\n",
    "        # Return fraction of sum of all windows' heights (without overlap), on all floors to the overall length of building\n",
    "        return np.sum(detection_series)/height\n",
    "    \n",
    "    def aggregate_fraction_height(self, img):\n",
    "        # Function that calculates proportion of sum of all windows' heights (divided by the number of floors) \n",
    "        # to the overall length of building\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        height = gray.shape[0]\n",
    "        width = gray.shape[1]\n",
    "\n",
    "        # threshold optimized (via hit and trial) for the generated images\n",
    "        ret, thresh = cv2.threshold(gray, self.threshold, 255, 0)\n",
    "\n",
    "        # Contours is a tree of lists of points which describe each contour\n",
    "        contours, h = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Create a list storing quadrilaterals that represent openings\n",
    "        quadrilaterals = []\n",
    "        for i in range(len(contours)):\n",
    "\n",
    "            # Contour approximation will mark four vertices of a quadrilateral\n",
    "            polygon = cv2.approxPolyDP(contours[i],0.01*cv2.arcLength(contours[i],True),True)\n",
    "            # filtering only those openings that are quadrilaterals\n",
    "            if len(polygon) == 4:\n",
    "                quadrilaterals.append(polygon) \n",
    "\n",
    "        redflag = [0]*len(quadrilaterals)\n",
    "\n",
    "        # Detect and delete quadrilaterals outside the house which should not be counted as openings\n",
    "        for i in range(len(quadrilaterals)):\n",
    "            q = quadrilaterals[i]\n",
    "            for j in range(4):\n",
    "                if abs(q[j][0][0] - gray.shape[1]) < self.corner_margin or abs(q[j][0][0]) < self.corner_margin:\n",
    "                    redflag[i] = 1\n",
    "\n",
    "        # set aggregate height = 0 before the loop that is going to account for the height of each opening\n",
    "        aggregate_height = 0\n",
    "\n",
    "        # The height of a side should be the larger y cordinate of the top vertics \n",
    "        # minus the y cordinate of the bottom vertics\n",
    "        for i in range(len(quadrilaterals)):\n",
    "            q = quadrilaterals[i]\n",
    "            if redflag[i]!=1:\n",
    "                y_min = np.min(q[:,0,1])\n",
    "                y_max = np.max(q[:,0,1])\n",
    "                aggregate_height = aggregate_height + (y_max-y_min)\n",
    "\n",
    "        # To be careful:\n",
    "        # Width of each floor is same and equal to the width of the house\n",
    "        # However, height of each floor = height of the house / 3\n",
    "        # So we actually don't need the number of floors to calculate the average\n",
    "\n",
    "        # there is no notion of vertical floors, so this ratio is going to exceed one\n",
    "        # Return the ratio of: sum of all windows' height to the total height of the building\n",
    "        return aggregate_height/height\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing feature vectors for all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = Feature_Extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8371/8371 [00:09<00:00, 871.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a list called 'levels' to store number of floors for each building\n",
    "levels = []\n",
    "for i in tqdm(range(n)):\n",
    "    n_level = feature_extractor.count_level(list_img[i])\n",
    "    levels.append(n_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2037, 3: 3763, 2: 2536, 4: 35})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8371/8371 [00:05<00:00, 1403.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a list called 'openings' to store number of openings\n",
    "openings = []\n",
    "for i in tqdm(range(n)):\n",
    "    openings.append(feature_extractor.count_openings(list_img[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 628,\n",
       "         2: 1475,\n",
       "         4: 1056,\n",
       "         6: 1791,\n",
       "         3: 1654,\n",
       "         5: 389,\n",
       "         7: 276,\n",
       "         9: 881,\n",
       "         8: 220,\n",
       "         0.0: 1})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(openings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8371/8371 [00:06<00:00, 1232.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a list called 'fraction_widths' to store proportion of sum of all windows' widths (without overlap), (on all floors) \n",
    "# to the overall width of building\n",
    "fraction_widths = []\n",
    "for i in tqdm(range(len(list_img))):\n",
    "    fraction_widths.append(feature_extractor.fraction_width(list_img[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8371/8371 [00:16<00:00, 518.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a list called 'avg_fraction_widths' to store proportion of average of all windows' widths (over all floors) \n",
    "# to the overall width of building\n",
    "avg_fraction_widths = []\n",
    "for i in tqdm(range(len(list_img))):\n",
    "    avg_fraction_widths.append(feature_extractor.avg_fraction_width(list_img[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8371/8371 [00:06<00:00, 1220.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a list called 'fraction_heights' to store proportion of sum of all windows' heights (without overlap), on all floors \n",
    "# to the overall height of building\n",
    "fraction_heights = []\n",
    "for i in tqdm(range(len(list_img))):\n",
    "    fraction_heights.append(feature_extractor.fraction_height(list_img[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8371/8371 [00:06<00:00, 1339.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a list called 'aggregate_fraction_heights' to store proportion of sum of all windows' heights (on all floors) \n",
    "# to the overall height of building\n",
    "aggregate_fraction_heights = []\n",
    "for i in tqdm(range(len(list_img))):\n",
    "    aggregate_fraction_heights.append(feature_extractor.aggregate_fraction_height(list_img[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8371/8371 [00:00<00:00, 555704.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a list called 'img_widths' to store the pixel widths of all images\n",
    "img_widths = []\n",
    "for i in tqdm(range(len(list_img))):\n",
    "    img_widths.append(feature_extractor.img_width(list_img[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8371/8371 [00:00<00:00, 570105.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a list called 'img_heights' to store the pixel widths of all images\n",
    "img_heights = []\n",
    "for i in tqdm(range(len(list_img))):\n",
    "    img_heights.append(feature_extractor.img_height(list_img[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1007, 1008, 1011, 1016, 1026, 103, 1031, 1039, 1047, 105]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract image index (four digit number)\n",
    "files_go_idx = []\n",
    "for file in filepaths_go:\n",
    "    files_go_idx.append(int(file.split(\"Img\")[1].split(\".\")[0]))\n",
    "files_go_idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 10, 100, 1000, 1001, 1002, 1003, 1004, 1005, 1006]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_nogo_idx = []\n",
    "for file in filepaths_nogo:\n",
    "    if \"Img\" in file:\n",
    "        files_nogo_idx.append(int(file.split(\"Img\")[1].split(\".\")[0]))\n",
    "files_nogo_idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = files_go_idx + files_nogo_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a a dataframe with all features and image index as columns\n",
    "dic = {\"filename\":files, \"levels\":levels, \"openings\":openings, \"fraction_widths\":fraction_widths, \n",
    "       \"avg_fraction_widths\":avg_fraction_widths, \"fraction_heights\":fraction_heights, \n",
    "       \"aggregate_fraction_heights\":aggregate_fraction_heights, \"img_widths\":img_widths, \"img_heights\":img_heights}\n",
    "df = pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>levels</th>\n",
       "      <th>openings</th>\n",
       "      <th>fraction_widths</th>\n",
       "      <th>avg_fraction_widths</th>\n",
       "      <th>fraction_heights</th>\n",
       "      <th>aggregate_fraction_heights</th>\n",
       "      <th>img_widths</th>\n",
       "      <th>img_heights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1007</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.096045</td>\n",
       "      <td>0.096045</td>\n",
       "      <td>0.407767</td>\n",
       "      <td>0.407767</td>\n",
       "      <td>531</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1008</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.105461</td>\n",
       "      <td>0.105461</td>\n",
       "      <td>0.432990</td>\n",
       "      <td>0.432990</td>\n",
       "      <td>531</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1011</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.167608</td>\n",
       "      <td>0.167608</td>\n",
       "      <td>0.461165</td>\n",
       "      <td>0.665049</td>\n",
       "      <td>531</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.269492</td>\n",
       "      <td>0.089831</td>\n",
       "      <td>0.336927</td>\n",
       "      <td>0.412399</td>\n",
       "      <td>590</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1026</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.133710</td>\n",
       "      <td>0.097928</td>\n",
       "      <td>0.410494</td>\n",
       "      <td>0.410494</td>\n",
       "      <td>531</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   filename  levels  openings  fraction_widths  avg_fraction_widths  \\\n",
       "0      1007       1       1.0         0.096045             0.096045   \n",
       "1      1008       1       1.0         0.105461             0.105461   \n",
       "2      1011       1       2.0         0.167608             0.167608   \n",
       "3      1016       3       4.0         0.269492             0.089831   \n",
       "4      1026       2       2.0         0.133710             0.097928   \n",
       "\n",
       "   fraction_heights  aggregate_fraction_heights  img_widths  img_heights  \n",
       "0          0.407767                    0.407767         531          206  \n",
       "1          0.432990                    0.432990         531          194  \n",
       "2          0.461165                    0.665049         531          206  \n",
       "3          0.336927                    0.412399         590          371  \n",
       "4          0.410494                    0.410494         531          324  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add GO/NoGo column to label each image\n",
    "df['Go/NoGo']=df['filename'].apply(lambda x: 1 if x in files_go_idx else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>levels</th>\n",
       "      <th>openings</th>\n",
       "      <th>fraction_widths</th>\n",
       "      <th>avg_fraction_widths</th>\n",
       "      <th>fraction_heights</th>\n",
       "      <th>aggregate_fraction_heights</th>\n",
       "      <th>img_widths</th>\n",
       "      <th>img_heights</th>\n",
       "      <th>Go/NoGo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1007</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.096045</td>\n",
       "      <td>0.096045</td>\n",
       "      <td>0.407767</td>\n",
       "      <td>0.407767</td>\n",
       "      <td>531</td>\n",
       "      <td>206</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1008</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.105461</td>\n",
       "      <td>0.105461</td>\n",
       "      <td>0.432990</td>\n",
       "      <td>0.432990</td>\n",
       "      <td>531</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1011</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.167608</td>\n",
       "      <td>0.167608</td>\n",
       "      <td>0.461165</td>\n",
       "      <td>0.665049</td>\n",
       "      <td>531</td>\n",
       "      <td>206</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.269492</td>\n",
       "      <td>0.089831</td>\n",
       "      <td>0.336927</td>\n",
       "      <td>0.412399</td>\n",
       "      <td>590</td>\n",
       "      <td>371</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1026</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.133710</td>\n",
       "      <td>0.097928</td>\n",
       "      <td>0.410494</td>\n",
       "      <td>0.410494</td>\n",
       "      <td>531</td>\n",
       "      <td>324</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   filename  levels  openings  fraction_widths  avg_fraction_widths  \\\n",
       "0      1007       1       1.0         0.096045             0.096045   \n",
       "1      1008       1       1.0         0.105461             0.105461   \n",
       "2      1011       1       2.0         0.167608             0.167608   \n",
       "3      1016       3       4.0         0.269492             0.089831   \n",
       "4      1026       2       2.0         0.133710             0.097928   \n",
       "\n",
       "   fraction_heights  aggregate_fraction_heights  img_widths  img_heights  \\\n",
       "0          0.407767                    0.407767         531          206   \n",
       "1          0.432990                    0.432990         531          194   \n",
       "2          0.461165                    0.665049         531          206   \n",
       "3          0.336927                    0.412399         590          371   \n",
       "4          0.410494                    0.410494         531          324   \n",
       "\n",
       "   Go/NoGo  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting in logistic model and evaluate the performance(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc [:, 1:9] , df['Go/NoGo'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalizing the feature vectors\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X_train))\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyperparameter tuning\n",
    "logreg = LogisticRegression(solver = 'liblinear', class_weight = 'balanced')\n",
    "# balanced weights for class imbalance\n",
    "penalty = ['l1', 'l2']\n",
    "C =np.logspace(-2, 4, 10)\n",
    "hyperparameters = dict(C=C, penalty=penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid search using 5-fold cross validation\n",
    "clf = GridSearchCV(logreg, hyperparameters, cv=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l1\n",
      "Best C: 0.046415888336127774\n"
     ]
    }
   ],
   "source": [
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 79.66%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of logistic regression classifier on test set: {:.2f}%'.format(100*best_model.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1219,  296],\n",
       "       [ 215,  782]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Confustion Matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:build_change]",
   "language": "python",
   "name": "conda-env-build_change-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
